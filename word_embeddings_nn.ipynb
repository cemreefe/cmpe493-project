{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 493-playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemreefe/cmpe493-project/blob/main/word_embeddings_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVZLCZdmBY78",
        "outputId": "c3b61959-2675-43e6-b0c0-2186e92906dd"
      },
      "source": [
        "!pip3 install xmltodict\n",
        "\n",
        "import os\n",
        "import io   \n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import pickle\n",
        "import string\n",
        "import tarfile\n",
        "import xmltodict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (0.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF1KRp5a_KRn",
        "outputId": "0ce71c5c-fe31-4720-f8b3-9e3da8b374e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ5AG9XTGv3c"
      },
      "source": [
        "def read_file(path):\n",
        "  with open(path, 'r') as f:\n",
        "    return f.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCj1rJ6bAjC2"
      },
      "source": [
        "if not os.path.exists('drive/MyDrive/CMPE/CMPE493'):\n",
        "  os.makedirs('drive/MyDrive/CMPE/CMPE493')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm-aEzfN-53E"
      },
      "source": [
        "if not os.path.exists('drive/MyDrive/CMPE/CMPE493/topics-rnd5.xml'):\n",
        "  !curl https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml --output drive/MyDrive/CMPE/CMPE493/topics-rnd5.xml\n",
        "\n",
        "if not os.path.exists('drive/MyDrive/CMPE/CMPE493/qrels-covid_d5_j0.5-5.txt'):\n",
        "  !curl https://ir.nist.gov/covidSubmit/data/qrels-covid_d5_j0.5-5.txt --output drive/MyDrive/CMPE/CMPE493/qrels-covid_d5_j0.5-5.txt\n",
        "\n",
        "if not os.path.exists('drive/MyDrive/CMPE/CMPE493/cord-19_2020-07-16.tar.gz'):\n",
        "  !curl https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases/cord-19_2020-07-16.tar.gz --output drive/MyDrive/CMPE/CMPE493/cord-19_2020-07-16.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcQnwTCRBbv7"
      },
      "source": [
        "if not os.path.exists('2020-07-16'):\n",
        "  tar = tarfile.open('drive/MyDrive/CMPE/CMPE493/cord-19_2020-07-16.tar.gz', \"r:gz\")\n",
        "  tar.extractall()\n",
        "  tar.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_psEwqmCBb2",
        "outputId": "9b9351b1-aec0-4ebf-ddc6-4ada9dafeb33"
      },
      "source": [
        "df_metadata = pd.read_csv('2020-07-16/metadata.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYc9bGgtOx-u"
      },
      "source": [
        "del df_metadata['sha'], df_metadata['source_x'], df_metadata['doi'], df_metadata['pmcid'], df_metadata['pubmed_id'], df_metadata['license'], df_metadata['publish_time'], df_metadata['authors'], df_metadata['journal'], df_metadata['mag_id'], df_metadata['who_covidence_id'], df_metadata['arxiv_id'], df_metadata['pdf_json_files'], df_metadata['pmc_json_files'], df_metadata['url'], df_metadata['s2_id']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKt-HNIOji_W"
      },
      "source": [
        "df_metadata.drop_duplicates(subset='cord_uid', keep='first', inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I7QIYPDmov8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "e800ca1e-1b45-4397-d501-f6f9d6dab274"
      },
      "source": [
        "df_metadata"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cord_uid</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ug7v899j</td>\n",
              "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
              "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02tnwd4m</td>\n",
              "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
              "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ejv2xln0</td>\n",
              "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
              "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2b73a28n</td>\n",
              "      <td>Role of endothelin-1 in lung disease</td>\n",
              "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9785vg6d</td>\n",
              "      <td>Gene expression in epithelial cells in respons...</td>\n",
              "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192504</th>\n",
              "      <td>z4ro6lmh</td>\n",
              "      <td>Rapid radiological improvement of COVID-19 pne...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192505</th>\n",
              "      <td>hi8k8wvb</td>\n",
              "      <td>SARS E protein in phospholipid bilayers: an an...</td>\n",
              "      <td>Abstract We report on an anomalous X-ray refle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192506</th>\n",
              "      <td>ma3ndg41</td>\n",
              "      <td>Italian Society of Interventional Cardiology (...</td>\n",
              "      <td>COVID‐19 pandemic raised the issue to guarante...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192507</th>\n",
              "      <td>wh10285j</td>\n",
              "      <td>Nimble, Together: A Training Program's Respons...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192508</th>\n",
              "      <td>pnl9th2c</td>\n",
              "      <td>Vascular Life during the COVID-19 Pandemic Rem...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>191175 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        cord_uid  ...                                           abstract\n",
              "0       ug7v899j  ...  OBJECTIVE: This retrospective chart review des...\n",
              "1       02tnwd4m  ...  Inflammatory diseases of the respiratory tract...\n",
              "2       ejv2xln0  ...  Surfactant protein-D (SP-D) participates in th...\n",
              "3       2b73a28n  ...  Endothelin-1 (ET-1) is a 21 amino acid peptide...\n",
              "4       9785vg6d  ...  Respiratory syncytial virus (RSV) and pneumoni...\n",
              "...          ...  ...                                                ...\n",
              "192504  z4ro6lmh  ...                                                NaN\n",
              "192505  hi8k8wvb  ...  Abstract We report on an anomalous X-ray refle...\n",
              "192506  ma3ndg41  ...  COVID‐19 pandemic raised the issue to guarante...\n",
              "192507  wh10285j  ...                                                NaN\n",
              "192508  pnl9th2c  ...                                                NaN\n",
              "\n",
              "[191175 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "EGkG7afREkla",
        "outputId": "e7dbee32-d67e-4c6b-ddaa-b018665bb7dd"
      },
      "source": [
        "topic_relevances = 'topic iter document_id judgement\\n' + read_file('drive/MyDrive/CMPE/CMPE493/qrels-covid_d5_j0.5-5.txt')\n",
        "\n",
        "df_relevances = pd.read_csv(  io.StringIO(topic_relevances)  , sep=\" \")\n",
        "del df_relevances['iter']\n",
        "\n",
        "df_relevances"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>document_id</th>\n",
              "      <th>judgement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>005b2j4b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00fmeepz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>010vptx3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0194oljo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>021q9884</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69313</th>\n",
              "      <td>50</td>\n",
              "      <td>zvop8bxh</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69314</th>\n",
              "      <td>50</td>\n",
              "      <td>zwf26o63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69315</th>\n",
              "      <td>50</td>\n",
              "      <td>zwsvlnwe</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69316</th>\n",
              "      <td>50</td>\n",
              "      <td>zxr01yln</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69317</th>\n",
              "      <td>50</td>\n",
              "      <td>zz8wvos9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69318 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       topic document_id  judgement\n",
              "0          1    005b2j4b          2\n",
              "1          1    00fmeepz          1\n",
              "2          1    010vptx3          2\n",
              "3          1    0194oljo          1\n",
              "4          1    021q9884          1\n",
              "...      ...         ...        ...\n",
              "69313     50    zvop8bxh          2\n",
              "69314     50    zwf26o63          1\n",
              "69315     50    zwsvlnwe          0\n",
              "69316     50    zxr01yln          1\n",
              "69317     50    zz8wvos9          1\n",
              "\n",
              "[69318 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQ3a3yIItFa"
      },
      "source": [
        "topics_obj = xmltodict.parse(read_file('drive/MyDrive/CMPE/CMPE493/topics-rnd5.xml'))\n",
        "topics     = json.loads(json.dumps(topics_obj))\n",
        "\n",
        "topics_dict = {}\n",
        "for topic in topics['topics']['topic']:\n",
        "  # a topic has the following fields:\n",
        "  #  * @number\n",
        "  #  * narrative\n",
        "  #  * query\n",
        "  #  * question\n",
        "  topics_dict[topic['@number']] = topic['query'] + ' ' + topic['question'] + ' ' + topic['narrative']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwwehnTLLIyy"
      },
      "source": [
        "# Data so far\n",
        "\n",
        "* `topics_dict` \n",
        "      has `topic-id` for keys, and topic description for values\n",
        "* `df_relevances` \n",
        "      has the following three columns:\n",
        "      topic\tdocument-id\tjudgement\n",
        "* `df_metadata`\n",
        "      holds information about the documents\n",
        "      has the following three columns (others are deleted):\n",
        "      cord_uid\ttitle\tabstract\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moo9WB8LY5R4",
        "outputId": "4b2d272b-49dc-4630-eaa1-a649062bb7df"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfBFOSwlX9w5"
      },
      "source": [
        "docs = np.array(df_metadata)\n",
        "contents = {}\n",
        "\n",
        "# create a contents dictionary with all contents of a document\n",
        "for doc in docs:\n",
        "  contents[doc[0]] = f'{doc[1]} {doc[2]}'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7h_TY6PvwWY"
      },
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "# preprocessing\n",
        "# case folding\n",
        "# punctuation removal\n",
        "# number deletion\n",
        "# stemming & stopword removal\n",
        "def preprocess(s):\n",
        "  s = s.casefold()\n",
        "  s = s.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
        "  s = [porter_stemmer.stem(word) for word in s.split() if word not in sw and word != 'nan']\n",
        "  return s"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4xzgaOSNnz1"
      },
      "source": [
        "### `contents` is a dictionary with document id keys and f'{document title} {document content}' values.\n",
        "```\n",
        "document_id: f'{document_title} {document_content}'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1-SnUFDTmjZ"
      },
      "source": [
        "################################################## WORD EMBEDDINGS ##########################################################"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mCm_i31NjFn",
        "outputId": "e7095f2b-4446-48f2-c9eb-fcb9e14b12aa"
      },
      "source": [
        "# download spacy model\n",
        "!python3 -m spacy download en_core_web_md"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_ykgj7QsKv"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DGqizMqdMih"
      },
      "source": [
        "# load the spacy English model\n",
        "# disable unused parts of the spacy pipeline (to speed up the process)\n",
        "nlp_stripped = spacy.load('en_core_web_md', disable=['tagger', 'parser', 'ner', 'entity_linker', 'entity_ruler', 'textcat', 'lemmatizer', 'morphologizer', 'attribute_ruler', 'senter', 'sentencizer', 'tok2vec', 'transformer'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qad1XbxvsQ7P"
      },
      "source": [
        "# DISCLAIMER: our numerous trials have shown that preprocessing, \n",
        "# although costly, often results in a decrease in performance\n",
        "\n",
        "# whether or not to use preprocessing\n",
        "preprocessing = False"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3fDrTk8gqfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0e31d6-b515-4bfb-fab4-7b44cecc6933"
      },
      "source": [
        "%%time\n",
        "\n",
        "# takes around 3mins with preprocessing\n",
        "if preprocessing:\n",
        "  preprocessed_contents = list(map(preprocess, contents.values()))\n",
        "  preprocessed_topic_contents = list(map(preprocess, topics_dict.values()))\n",
        "else:\n",
        "  preprocessed_contents = list(contents.values())\n",
        "  preprocessed_topic_contents = list(topics_dict.values())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.09 ms, sys: 911 µs, total: 9 ms\n",
            "Wall time: 9.52 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GDjpRKAPkvF",
        "outputId": "9c573713-75bc-47d7-bef9-40e92ef48bd4"
      },
      "source": [
        "%%time\n",
        "\n",
        "# ~100 sec operation\n",
        "doc_content_list = []\n",
        "doc_content_list = list(nlp_stripped.pipe(preprocessed_contents))\n",
        "\n",
        "topic_content_list = []\n",
        "topic_content_list = list(nlp.pipe(preprocessed_topic_contents))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 38s, sys: 7.26 s, total: 1min 45s\n",
            "Wall time: 1min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UDSeKJTiQWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9ca710-b33a-47ae-8052-33e0bec62f1c"
      },
      "source": [
        "%%time\n",
        "\n",
        "# ~320 sec operation\n",
        "doc_vector_list   = list(map(lambda x: x.vector, doc_content_list))\n",
        "topic_vector_list = list(map(lambda x: x.vector, topic_content_list))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 14s, sys: 1.88 s, total: 5min 16s\n",
            "Wall time: 5min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIKDOqjrE7sU"
      },
      "source": [
        "del doc_content_list, topic_content_list, preprocessed_contents, preprocessed_topic_contents, df_metadata"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQTrpJuiIfG7"
      },
      "source": [
        "doc_vector_list_spacy   = doc_vector_list.copy()\n",
        "topic_vector_list_spacy = topic_vector_list.copy()"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzNzio0-MhwM"
      },
      "source": [
        "cos_sims_spacy = cosine_similarity(doc_vector_list_spacy, topic_vector_list_spacy)\n",
        "man_dist_spacy = manhattan_distances(doc_vector_list_spacy, topic_vector_list_spacy)\n",
        "euc_dist_spacy = euclidean_distances(doc_vector_list_spacy, topic_vector_list_spacy)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z51RDqWGYZpW"
      },
      "source": [
        "# True if we have a pretrained gensim embedding vectorizer and we want to use its vectors in addition to scapies'\n",
        "# the model is loaded and its vectors' data are appended to the datapoints during dataset creation\n",
        "# (this model is trained in the notebook `Gensim_Doc2Vec.ipynb`)\n",
        "use_gensim_vectors = True\n",
        "\n",
        "if use_gensim_vectors:\n",
        "\n",
        "  import gensim\n",
        "  \n",
        "  # load gensim model\n",
        "  model = gensim.models.Doc2Vec.load(\"./model_epoch_9\")\n",
        "\n",
        "  def get_corpus():\n",
        "    for i, (id, doc) in enumerate(contents.items()):\n",
        "      tokens = doc.split()\n",
        "      yield gensim.models.doc2vec.TaggedDocument(tokens, [id])\n",
        "\n",
        "  # load corpus\n",
        "  train_corpus = list(get_corpus())\n",
        "  \n",
        "  def get_doc_vectors():\n",
        "    for i,id in enumerate(contents.keys()):\n",
        "      yield model.infer_vector(train_corpus[i].words)\n",
        "\n",
        "  # calculate document vectors\n",
        "  doc_vector_list_gensim = list(get_doc_vectors())\n",
        "\n",
        "  def get_topic_vectors():\n",
        "    for topic in topics_dict.values():\n",
        "      yield model.infer_vector(preprocess(topic))\n",
        "\n",
        "  # calculate topic vectors\n",
        "  topic_vector_list_gensim = list(get_topic_vectors())\n",
        "\n",
        "  # get vector distances and similarities\n",
        "  cos_sims_gensim = cosine_similarity(doc_vector_list_gensim, topic_vector_list_gensim)\n",
        "  man_dist_gensim = manhattan_distances(doc_vector_list_gensim, topic_vector_list_gensim)\n",
        "  euc_dist_gensim = euclidean_distances(doc_vector_list_gensim, topic_vector_list_gensim)"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4BC744sEBzn",
        "outputId": "0954c78c-6515-41db-b03b-d181368d8f03"
      },
      "source": [
        "%%time\n",
        "\n",
        "# index lookup dictionary for document ids\n",
        "lookup_ck = {\n",
        "    key: i\n",
        "    for i, key in enumerate(contents.keys())\n",
        "}\n",
        "\n",
        "# index lookup dictionary for topic ids\n",
        "lookup_tk = {\n",
        "    int(key): i\n",
        "    for i, key in enumerate(topics_dict.keys())\n",
        "}\n",
        "\n",
        "# dataset\n",
        "X_all, y_all     = [], []\n",
        "X_train, y_train = [], []\n",
        "X_test, y_test   = [], []\n",
        "\n",
        "\n",
        "for row in np.array(df_relevances):\n",
        "  \n",
        "  ck_index = lookup_ck[row[1]]\n",
        "  tk_index = lookup_tk[row[0]]\n",
        "  \n",
        "  # a datapoint x in the dataset is an array of length 311:\n",
        "  x = np.hstack([\n",
        "    # gensim\n",
        "\n",
        "    \n",
        "    # the first 300 elements:\n",
        "    # the elementwise difference between the document and topic vectors\n",
        "    doc_vector_list_gensim[ck_index] - topic_vector_list_gensim[tk_index] if use_gensim_vectors else [],\n",
        "    # the other 11 elements are certain statistics about these vectors\n",
        "    [\n",
        "      # cosine similarity between the two vectors\n",
        "      cos_sims_gensim[ck_index, tk_index],\n",
        "      # manhattan distance between the two vectors\n",
        "      man_dist_gensim[ck_index, tk_index],\n",
        "      # euclidean distance between the two vectors\n",
        "      euc_dist_gensim[ck_index, tk_index],\n",
        "      # mean of the document vector\n",
        "      np.mean(doc_vector_list_gensim[ck_index]),\n",
        "      # mean of the topic vector\n",
        "      np.mean(topic_vector_list_gensim[tk_index]),\n",
        "      # mean of the absolute values of the document vector\n",
        "      np.mean(abs(doc_vector_list_gensim[ck_index])),\n",
        "      # mean of the absolute values of the topic vector\n",
        "      np.mean(abs(topic_vector_list_gensim[tk_index])),\n",
        "      # standard deviation of the document vector\n",
        "      np.std(doc_vector_list_gensim[ck_index]),\n",
        "      # standard deviation of the topic vector\n",
        "      np.std(topic_vector_list_gensim[tk_index]),\n",
        "      # standard deviation of the absolute valued document vector\n",
        "      np.std(abs(doc_vector_list_gensim[ck_index])),\n",
        "      # standard deviation of the absolute valued topic vector\n",
        "      np.std(abs(topic_vector_list_gensim[tk_index])),\n",
        "    ] if use_gensim_vectors else [],\n",
        "    \n",
        "    # spacy\n",
        "\n",
        "    # the first 300 elements:\n",
        "    # the elementwise difference between the document and topic vectors\n",
        "    doc_vector_list_spacy[ck_index] - topic_vector_list_spacy[tk_index],\n",
        "    # the other 11 elements are certain statistics about these vectors\n",
        "    [\n",
        "      # cosine similarity between the two vectors\n",
        "      cos_sims_spacy[ck_index, tk_index],\n",
        "      # manhattan distance between the two vectors\n",
        "      man_dist_spacy[ck_index, tk_index],\n",
        "      # euclidean distance between the two vectors\n",
        "      euc_dist_spacy[ck_index, tk_index],\n",
        "      # mean of the document vector\n",
        "      np.mean(doc_vector_list_spacy[ck_index]),\n",
        "      # mean of the topic vector\n",
        "      np.mean(topic_vector_list_spacy[tk_index]),\n",
        "      # mean of the absolute values of the document vector\n",
        "      np.mean(abs(doc_vector_list_spacy[ck_index])),\n",
        "      # mean of the absolute values of the topic vector\n",
        "      np.mean(abs(topic_vector_list_spacy[tk_index])),\n",
        "      # standard deviation of the document vector\n",
        "      np.std(doc_vector_list_spacy[ck_index]),\n",
        "      # standard deviation of the topic vector\n",
        "      np.std(topic_vector_list_[tk_index]),\n",
        "      # standard deviation of the absolute valued document vector\n",
        "      np.std(abs(doc_vector_list_spacy[ck_index])),\n",
        "      # standard deviation of the absolute valued topic vector\n",
        "      np.std(abs(topic_vector_list_spacy[tk_index])),\n",
        "    ]\n",
        "  ])\n",
        "  \n",
        "  if row[0] % 2:\n",
        "    X_train.append(x)\n",
        "    y_train.append(np.array([row[2]/2]))\n",
        "  else:\n",
        "    X_test.append(x)\n",
        "    y_test.append(np.array([row[2]/2]))\n",
        "  \n",
        "  X_all.append(x)\n",
        "  y_all.append(np.array([row[2]/2]))\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_all = np.array(X_all)\n",
        "y_all = np.array(y_all)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25 s, sys: 401 ms, total: 25.4 s\n",
            "Wall time: 25.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiipBQuDIgkk",
        "outputId": "31b64622-6fc4-4d92-b6d7-2482fa812ceb"
      },
      "source": [
        "print('train set X:', X_train.shape, 'y:', y_train.shape)\n",
        "print('test set  X:', X_test.shape, 'y:', y_test.shape)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set X: (35894, 372) y: (35894, 1)\n",
            "test set  X: (33424, 372) y: (33424, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq0qHme5GHRN",
        "outputId": "33287cd0-b10d-4d52-dd8a-dc3e436617cc"
      },
      "source": [
        "%%time \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# we will use a very small neural network because the data is easily overfitted\n",
        "# we will also make use of batch normalization and dropout (0.5)\n",
        "# Our data has 311 features, so the model will be:\n",
        "# 311 -> 4 -> 8 -> 1 (all dense layers)\n",
        "\n",
        "# define a sequential keras model\n",
        "model = Sequential()\n",
        "\n",
        "# layer 1\n",
        "model.add(Dense(4, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# layer 2\n",
        "model.add(Dense(8, activation='sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# layer 3\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# define early stopping to avoid unnecessary training and overfitting\n",
        "# return to best weights after stop\n",
        "# REF: https://stackoverflow.com/questions/48285129/saving-best-model-in-keras/48286003\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='min', restore_best_weights=True)\n",
        "mcp_save = ModelCheckpoint('mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-2, mode='min')\n",
        "\n",
        "\n",
        "\n",
        "# compile the keras model with mean square error loss\n",
        "model.compile(loss='mse', optimizer=Adam(learning_rate=1e-4), metrics=['mse'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "history = model.fit(\n",
        "    X_train[:], \n",
        "    y_train[:], \n",
        "    epochs=100, \n",
        "    batch_size=100, \n",
        "    verbose=1, \n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[\n",
        "      earlyStopping, \n",
        "      mcp_save, \n",
        "      #reduce_lr_loss\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/100\n",
            "359/359 [==============================] - 2s 3ms/step - loss: 0.2402 - mse: 0.2402 - val_loss: 0.1953 - val_mse: 0.1953\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.19528, saving model to mdl_wts.hdf5\n",
            "Epoch 2/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.2189 - mse: 0.2189 - val_loss: 0.1956 - val_mse: 0.1956\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19528\n",
            "Epoch 3/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.2047 - mse: 0.2047 - val_loss: 0.1891 - val_mse: 0.1891\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.19528 to 0.18908, saving model to mdl_wts.hdf5\n",
            "Epoch 4/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1918 - mse: 0.1918 - val_loss: 0.1852 - val_mse: 0.1852\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.18908 to 0.18518, saving model to mdl_wts.hdf5\n",
            "Epoch 5/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.1812 - val_mse: 0.1812\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18518 to 0.18122, saving model to mdl_wts.hdf5\n",
            "Epoch 6/100\n",
            "359/359 [==============================] - 2s 6ms/step - loss: 0.1784 - mse: 0.1784 - val_loss: 0.1754 - val_mse: 0.1754\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.18122 to 0.17537, saving model to mdl_wts.hdf5\n",
            "Epoch 7/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1726 - mse: 0.1726 - val_loss: 0.1745 - val_mse: 0.1745\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.17537 to 0.17446, saving model to mdl_wts.hdf5\n",
            "Epoch 8/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1663 - mse: 0.1663 - val_loss: 0.1703 - val_mse: 0.1703\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.17446 to 0.17028, saving model to mdl_wts.hdf5\n",
            "Epoch 9/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1668 - mse: 0.1668 - val_loss: 0.1682 - val_mse: 0.1682\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.17028 to 0.16822, saving model to mdl_wts.hdf5\n",
            "Epoch 10/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1614 - mse: 0.1614 - val_loss: 0.1667 - val_mse: 0.1667\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.16822 to 0.16668, saving model to mdl_wts.hdf5\n",
            "Epoch 11/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 0.1660 - val_mse: 0.1660\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.16668 to 0.16598, saving model to mdl_wts.hdf5\n",
            "Epoch 12/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1595 - mse: 0.1595 - val_loss: 0.1655 - val_mse: 0.1655\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.16598 to 0.16549, saving model to mdl_wts.hdf5\n",
            "Epoch 13/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1555 - mse: 0.1555 - val_loss: 0.1648 - val_mse: 0.1648\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.16549 to 0.16476, saving model to mdl_wts.hdf5\n",
            "Epoch 14/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1561 - mse: 0.1561 - val_loss: 0.1641 - val_mse: 0.1641\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16476 to 0.16412, saving model to mdl_wts.hdf5\n",
            "Epoch 15/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1539 - mse: 0.1539 - val_loss: 0.1633 - val_mse: 0.1633\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.16412 to 0.16335, saving model to mdl_wts.hdf5\n",
            "Epoch 16/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 0.1630 - val_mse: 0.1630\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.16335 to 0.16296, saving model to mdl_wts.hdf5\n",
            "Epoch 17/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1542 - mse: 0.1542 - val_loss: 0.1625 - val_mse: 0.1625\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.16296 to 0.16252, saving model to mdl_wts.hdf5\n",
            "Epoch 18/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1508 - mse: 0.1508 - val_loss: 0.1625 - val_mse: 0.1625\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.16252 to 0.16247, saving model to mdl_wts.hdf5\n",
            "Epoch 19/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1501 - mse: 0.1501 - val_loss: 0.1618 - val_mse: 0.1618\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.16247 to 0.16178, saving model to mdl_wts.hdf5\n",
            "Epoch 20/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1520 - mse: 0.1520 - val_loss: 0.1608 - val_mse: 0.1608\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.16178 to 0.16082, saving model to mdl_wts.hdf5\n",
            "Epoch 21/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1502 - mse: 0.1502 - val_loss: 0.1607 - val_mse: 0.1607\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.16082 to 0.16068, saving model to mdl_wts.hdf5\n",
            "Epoch 22/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1483 - mse: 0.1483 - val_loss: 0.1612 - val_mse: 0.1612\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.16068\n",
            "Epoch 23/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.1601 - val_mse: 0.1601\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.16068 to 0.16008, saving model to mdl_wts.hdf5\n",
            "Epoch 24/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1492 - mse: 0.1492 - val_loss: 0.1601 - val_mse: 0.1601\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.16008\n",
            "Epoch 25/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1506 - mse: 0.1506 - val_loss: 0.1596 - val_mse: 0.1596\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.16008 to 0.15962, saving model to mdl_wts.hdf5\n",
            "Epoch 26/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1485 - mse: 0.1485 - val_loss: 0.1595 - val_mse: 0.1595\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.15962 to 0.15950, saving model to mdl_wts.hdf5\n",
            "Epoch 27/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 0.1591 - val_mse: 0.1591\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.15950 to 0.15913, saving model to mdl_wts.hdf5\n",
            "Epoch 28/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1489 - mse: 0.1489 - val_loss: 0.1590 - val_mse: 0.1590\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.15913 to 0.15895, saving model to mdl_wts.hdf5\n",
            "Epoch 29/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1508 - mse: 0.1508 - val_loss: 0.1588 - val_mse: 0.1588\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.15895 to 0.15878, saving model to mdl_wts.hdf5\n",
            "Epoch 30/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1478 - mse: 0.1478 - val_loss: 0.1585 - val_mse: 0.1585\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.15878 to 0.15848, saving model to mdl_wts.hdf5\n",
            "Epoch 31/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1463 - mse: 0.1463 - val_loss: 0.1591 - val_mse: 0.1591\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.15848\n",
            "Epoch 32/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1485 - mse: 0.1485 - val_loss: 0.1582 - val_mse: 0.1582\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.15848 to 0.15824, saving model to mdl_wts.hdf5\n",
            "Epoch 33/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 0.1586 - val_mse: 0.1586\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.15824\n",
            "Epoch 34/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 0.1581 - val_mse: 0.1581\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.15824 to 0.15810, saving model to mdl_wts.hdf5\n",
            "Epoch 35/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.1581 - val_mse: 0.1581\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.15810 to 0.15807, saving model to mdl_wts.hdf5\n",
            "Epoch 36/100\n",
            "359/359 [==============================] - 2s 6ms/step - loss: 0.1463 - mse: 0.1463 - val_loss: 0.1581 - val_mse: 0.1581\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.15807\n",
            "Epoch 37/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 0.1580 - val_mse: 0.1580\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.15807 to 0.15799, saving model to mdl_wts.hdf5\n",
            "Epoch 38/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1459 - mse: 0.1459 - val_loss: 0.1583 - val_mse: 0.1583\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.15799\n",
            "Epoch 39/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1585 - val_mse: 0.1585\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.15799\n",
            "Epoch 40/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 0.1577 - val_mse: 0.1577\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.15799 to 0.15772, saving model to mdl_wts.hdf5\n",
            "Epoch 41/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 0.1577 - val_mse: 0.1577\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.15772 to 0.15770, saving model to mdl_wts.hdf5\n",
            "Epoch 42/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1473 - mse: 0.1473 - val_loss: 0.1576 - val_mse: 0.1576\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.15770 to 0.15759, saving model to mdl_wts.hdf5\n",
            "Epoch 43/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1459 - mse: 0.1459 - val_loss: 0.1577 - val_mse: 0.1577\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.15759\n",
            "Epoch 44/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 0.1579 - val_mse: 0.1579\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.15759\n",
            "Epoch 45/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.1573 - val_mse: 0.1573\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.15759 to 0.15733, saving model to mdl_wts.hdf5\n",
            "Epoch 46/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.1575 - val_mse: 0.1575\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.15733\n",
            "Epoch 47/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.1577 - val_mse: 0.1577\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.15733\n",
            "Epoch 48/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1476 - mse: 0.1476 - val_loss: 0.1579 - val_mse: 0.1579\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.15733\n",
            "Epoch 49/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1451 - mse: 0.1451 - val_loss: 0.1575 - val_mse: 0.1575\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.15733\n",
            "Epoch 50/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1479 - mse: 0.1479 - val_loss: 0.1575 - val_mse: 0.1575\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.15733\n",
            "Epoch 51/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1462 - mse: 0.1462 - val_loss: 0.1578 - val_mse: 0.1578\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.15733\n",
            "Epoch 52/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1452 - mse: 0.1452 - val_loss: 0.1579 - val_mse: 0.1579\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.15733\n",
            "Epoch 53/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.1575 - val_mse: 0.1575\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.15733\n",
            "Epoch 54/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1576 - val_mse: 0.1576\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.15733\n",
            "Epoch 55/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 0.1576 - val_mse: 0.1576\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.15733\n",
            "Epoch 56/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 0.1578 - val_mse: 0.1578\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.15733\n",
            "Epoch 57/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 0.1581 - val_mse: 0.1581\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.15733\n",
            "Epoch 58/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.1578 - val_mse: 0.1578\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.15733\n",
            "Epoch 59/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1576 - val_mse: 0.1576\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.15733\n",
            "Epoch 60/100\n",
            "359/359 [==============================] - 2s 6ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 0.1581 - val_mse: 0.1581\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.15733\n",
            "Epoch 61/100\n",
            "359/359 [==============================] - 2s 7ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.1588 - val_mse: 0.1588\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.15733\n",
            "Epoch 62/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1453 - mse: 0.1453 - val_loss: 0.1587 - val_mse: 0.1587\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.15733\n",
            "Epoch 63/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1439 - mse: 0.1439 - val_loss: 0.1590 - val_mse: 0.1590\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.15733\n",
            "Epoch 64/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1433 - mse: 0.1433 - val_loss: 0.1583 - val_mse: 0.1583\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.15733\n",
            "Epoch 65/100\n",
            "359/359 [==============================] - 1s 3ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 0.1592 - val_mse: 0.1592\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.15733\n",
            "CPU times: user 1min 28s, sys: 5.27 s, total: 1min 33s\n",
            "Wall time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "V8rNmitAVacp",
        "outputId": "80f687da-c6d3-4625-e9d4-921291d5214e"
      },
      "source": [
        "# plot loss history\n",
        "for key, hist in history.history.items():\n",
        "  if key == 'lr':\n",
        "    continue\n",
        "  plt.plot(hist, label=key)\n",
        "plt.legend()"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa9f8b0d828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWmI5g54DCIH",
        "outputId": "8beddf97-f5c8-4874-f2c7-267630d1880c"
      },
      "source": [
        "pred_all = model.predict(X_all)\n",
        "\n",
        "rel_nn = np.array(rel)\n",
        "for i in range(len(rel_nn)):\n",
        "  rel_nn[i][-1] = pred_all[i][0]\n",
        "\n",
        "rel_nn"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, '005b2j4b', 0.32536322],\n",
              "       [1, '00fmeepz', 0.3016779],\n",
              "       [1, '010vptx3', 0.35507375],\n",
              "       ...,\n",
              "       [50, 'zwsvlnwe', 0.45086873],\n",
              "       [50, 'zxr01yln', 0.2726978],\n",
              "       [50, 'zz8wvos9', 0.46131325]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_JCST4OK5h"
      },
      "source": [
        "results = []\n",
        "for i, row in enumerate(rel_nn):\n",
        "  if not row[0] % 2:\n",
        "    results.append(f'{row[0]} 0 {row[1]} 0 {row[2]} 0')"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjGlUWF7Tef8",
        "outputId": "9793aea3-79d1-4c3a-86fe-dc3d9c52477e"
      },
      "source": [
        "results[:10]"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2 0 01goni72 0 0.38876086473464966 0',\n",
              " '2 0 01yc7lzk 0 0.26705682277679443 0',\n",
              " '2 0 02cy1s8x 0 0.20740172266960144 0',\n",
              " '2 0 02f0opkr 0 0.3049258887767792 0',\n",
              " '2 0 03h85lvy 0 0.3413306474685669 0',\n",
              " '2 0 03id5o2g 0 0.1917247772216797 0',\n",
              " '2 0 03s9spbi 0 0.4109969139099121 0',\n",
              " '2 0 04awj06g 0 0.29111987352371216 0',\n",
              " '2 0 04rbtmmi 0 0.36599379777908325 0',\n",
              " '2 0 084o1dmp 0 0.20988479256629944 0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8r9P5RDSelZ"
      },
      "source": [
        "# Write results to file\n",
        "with open('results_we_nn_nprep_bothmodels_2.txt', 'w') as f:\n",
        "    f.write('\\n'.join(results))"
      ],
      "execution_count": 255,
      "outputs": []
    }
  ]
}